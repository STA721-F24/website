{
  "hash": "8fca384773da2f01293d4705aed82deb",
  "result": {
    "engine": "knitr",
    "markdown": "---\nsubtitle: \"STA 721: Lecture 14\"\ntitle: \"Hypothesis Testing Related to SubModels\"\nauthor: \"Merlise Clyde (clyde@duke.edu)\"\ninstitute: \"Duke University\"\nformat: \n  revealjs:\n    theme: [simple, custom.scss]\n    slide-number: true\n    incremental: true\n    scrollable: false\n    controls: true\n    fragments: true\n    preview-links: auto\n    smaller: true\n    logo: ../../img/icon.png\n    footer: <https://sta721-F24.github.io/website/>\n    chalkboard: \n      boardmarker-width: 1\n      chalk-width: 2\n      chalk-effect: 0\n    embed-resources: false\n    include-in-header: mathjax-eq.html\nhtml-math-method:\n    method: mathjax\n    url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\neditor: \n  markdown: \n    wrap: 72\nexecute: \n  echo: false\nnumber-sections: false\nfilters:\n  - custom-numbered-blocks  \ncustom-numbered-blocks:\n  groups:\n    thmlike:\n      colors: [948bde, 584eab]\n      boxstyle: foldbox.simple\n      collapse: false\n      listin: [mathstuff]\n    todos: default  \n  classes:\n    Theorem:\n      group: thmlike\n      numbered: false\n    Lemma:\n      group: thmlike\n      numbered: false\n    Corollary:\n      group: thmlike\n      numbered: false\n    Proposition:\n      group: thmlike\n      numbered: false      \n    Proof:\n      group: thmlike\n      numbered: false\n      collapse: false   \n    Exercise:\n      group: thmlike\n      numbered: false\n    Definition:\n      group: thmlike\n      numbered: false\n      colors: [d999d3, a01793]\n    Feature: \n       numbered: false\n    TODO:\n      label: \"To do\"\n      colors: [e7b1b4, 8c3236]\n      group: todos\n      listin: [stilltodo]\n    DONE:\n      label: \"Done\"\n      colors: [cce7b1, 86b754]  \n      group: todos  \n---\n\n\n\n\n\n## Outline\n\n\\usepackage{xcolor}\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\DeclareMathOperator{\\sgn}{sgn}\n\\newcommand{\\e}{\\mathbf{e}}\n\\newcommand{\\Mb}{\\mathbf{M}}\n\\renewcommand{\\P}{\\mathbf{P}}\n\\newcommand{\\F}{\\mathbf{F}}\n\\newcommand{\\R}{\\textsf{R}}\n\\newcommand{\\mat}[1] {\\mathbf{#1}}\n\\newcommand{\\pen}{\\textsf{pen}}\n\\newcommand{\\E}{\\textsf{E}}\n\\newcommand{\\SE}{\\textsf{SE}}\n\\newcommand{\\SSE}{\\textsf{SSE}}\n\\newcommand{\\RSS}{\\textsf{RSS}}\n\\newcommand{\\FSS}{\\textsf{FSS}}\n\\renewcommand{\\SS}{\\textsf{SS}}\n\\newcommand{\\MSE}{\\textsf{MSE}}\n\\newcommand{\\SSR}{\\textsf{SSR}}\n\\newcommand{\\Be}{\\textsf{Beta}}\n\\newcommand{\\St}{\\textsf{St}}\n\\newcommand{\\Ca}{\\textsf{C}}\n\\newcommand{\\Lv}{\\textsf{Lévy}}\n\\newcommand{\\Exp}{\\textsf{Exp}}\n\\newcommand{\\GDP}{\\textsf{GDP}}\n\\newcommand{\\NcSt}{\\textsf{NcSt}}\n\\newcommand{\\Bin}{\\textsf{Bin}}\n\\newcommand{\\NB}{\\textsf{NegBin}}\n\\newcommand{\\Mult}{\\textsf{MultNom}}\n\\renewcommand{\\NG}{\\textsf{NG}}\n\\newcommand{\\N}{\\textsf{N}}\n\\newcommand{\\Ber}{\\textsf{Ber}}\n\\newcommand{\\Poi}{\\textsf{Poi}}\n\\newcommand{\\Gam}{\\textsf{Gamma}}\n\\newcommand{\\BB}{\\textsf{BB}}\n\\newcommand{\\BF}{\\textsf{BF}}\n\\newcommand{\\Gm}{\\textsf{G}}\n\\newcommand{\\Un}{\\textsf{Unif}}\n\\newcommand{\\Ex}{\\textsf{Exp}}\n\\newcommand{\\DE}{\\textsf{DE}}\n\\newcommand{\\tr}{\\textsf{tr}}\n\\newcommand{\\cF}{{\\cal{F}}}\n\\newcommand{\\cL}{{\\cal{L}}}\n\\newcommand{\\cI}{{\\cal{I}}}\n\\newcommand{\\cB}{{\\cal{B}}}\n\\newcommand{\\cP}{{\\cal{P}}}\n\\newcommand{\\bbR}{\\mathbb{R}}\n\\newcommand{\\bbN}{\\mathbb{N}}\n\\newcommand{\\pperp}{\\mathrel{{\\rlap{$\\,\\perp$}\\perp\\,\\,}}}\n\\newcommand{\\OFP}{(\\Omega,\\cF, \\P)}\n\\newcommand{\\eps}{\\boldsymbol{\\epsilon}}\n\\def\\ehat{\\hat{\\boldsymbol{\\epsilon}}}\n\\newcommand{\\Psib}{\\boldsymbol{\\Psi}}\n\\newcommand{\\Omegab}{\\boldsymbol{\\Omega}}\n\\newcommand{\\1}{\\mathbf{1}_n}\n\\newcommand{\\gap}{\\vspace{8mm}}\n\\newcommand{\\ind}{\\mathrel{\\mathop{\\sim}\\limits^{\\rm ind}}}\n\\newcommand{\\iid}{\\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}}\n\\newcommand{\\simiid}{\\ensuremath{\\mathrel{\\mathop{\\sim}\\limits^{\\rm\niid}}}}\n\\newcommand{\\eqindis}{\\mathrel{\\mathop{=}\\limits^{\\rm D}}}\n\\newcommand{\\SSZ}{S_{zz}}\n\\newcommand{\\SZW}{S_{zw}}\n\\newcommand{\\Var}{\\textsf{Var}}\n\\newcommand{\\corr}{\\textsf{corr}}\n\\newcommand{\\cov}{\\textsf{cov}}\n\\newcommand{\\diag}{\\textsf{diag}}\n\\newcommand{\\var}{\\textsf{var}}\n\\newcommand{\\Cov}{\\textsf{Cov}}\n\\newcommand{\\Sam}{{\\cal S}}\n\\newcommand{\\VS}{{\\cal V}}\n\\def\\H{\\mathbf{H}}\n\\newcommand{\\I}{\\mathbf{I}}\n\\newcommand{\\Y}{\\mathbf{Y}}\n\\newcommand{\\tY}{\\tilde{\\mathbf{Y}}}\n\\newcommand{\\Yhat}{\\hat{\\mathbf{Y}}}\n\\newcommand{\\yhat}{\\hat{\\mathbf{y}}}\n\\newcommand{\\Yobs}{\\mathbf{Y}_{{\\cal S}}}\n\\newcommand{\\barYobs}{\\bar{Y}_{{\\cal S}}}\n\\newcommand{\\barYmiss}{\\bar{Y}_{{\\cal S}^c}}\n\\def\\bv{\\mathbf{b}}\n\\def\\X{\\mathbf{X}}\n\\def\\XtX{\\X^T\\X}\n\\def\\tX{\\tilde{\\mathbf{X}}}\n\\def\\x{\\mathbf{x}}\n\\def\\xbar{\\bar{\\mathbf{x}}}\n\\def\\Xbar{\\bar{\\mathbf{X}}}\n\\def\\Xg{\\mathbf{X}_{\\boldsymbol{\\gamma}}}\n\\def\\Ybar{\\bar{\\Y}}\n\\def\\ybar{\\bar{y}}\n\\def\\y{\\mathbf{y}}\n\\def\\Yf{\\mathbf{Y_f}}\n\\def\\W{\\mathbf{W}}\n\\def\\L{\\mathbf{L}}\n\\def\\m{\\mathbf{m}}\n\\def\\n{\\mathbf{n}}\n\\def\\w{\\mathbf{w}}\n\\def\\U{\\mathbf{U}}\n\\def\\V{\\mathbf{V}}\n\\def\\Q{\\mathbf{Q}}\n\\def\\Z{\\mathbf{Z}}\n\\def\\z{\\mathbf{z}}\n\\def\\v{\\mathbf{v}}\n\\def\\u{\\mathbf{u}}\n\n\\def\\zero{\\mathbf{0}}\n\\def\\one{\\mathbf{1}}\n\\newcommand{\\taub}{\\boldsymbol{\\tau}}\n\\newcommand{\\betav}{\\boldsymbol{\\beta}}\n\\newcommand{\\alphav}{\\boldsymbol{\\alpha}}\n\\newcommand{\\bfomega}{\\boldsymbol{\\omega}}\n\\newcommand{\\bfchi}{\\boldsymbol{\\chi}}\n\\newcommand{\\bfLambda}{\\boldsymbol{\\Lambda}}\n\\newcommand{\\Lmea}{{\\cal L}} \n\\newcommand{\\scale}{\\bflambda} \n\\newcommand{\\Scale}{\\bfLambda} \n\\newcommand{\\bfscale}{\\bflambda} \n\\newcommand{\\mean}{\\bfchi}\n\\newcommand{\\loc}{\\bfchi}\n\\newcommand{\\bfmean}{\\bfchi}\n\\newcommand{\\bfx}{\\x}\n\\renewcommand{\\k}{g}\n\\newcommand{\\Gen}{{\\cal G}}\n\\newcommand{\\Levy}{L{\\'e}vy}\n\\def\\bfChi    {\\boldsymbol{\\Chi}}\n\\def\\bfOmega  {\\boldsymbol{\\Omega}}\n\\newcommand{\\Po}{\\mbox{\\sf P}}\n\\newcommand{\\A}{\\mathbf{A}}\n\\def\\a{\\mathbf{a}}\n\\def\\K{\\mathbf{K}}\n\\newcommand{\\B}{\\mathbf{B}}\n\\def\\b{\\boldsymbol{\\beta}}\n\\def\\bhat{\\hat{\\boldsymbol{\\beta}}}\n\\def\\btilde{\\tilde{\\boldsymbol{\\beta}}}\n\\def\\tb{\\boldsymbol{\\theta}}\n\\def\\bg{\\boldsymbol{\\beta_\\gamma}}\n\\def\\bgnot{\\boldsymbol{\\beta_{(-\\gamma)}}}\n\\def\\mub{\\boldsymbol{\\mu}}\n\\def\\tmub{\\tilde{\\boldsymbol{\\mu}}}\n\\def\\muhat{\\hat{\\boldsymbol{\\mu}}}\n\\def\\tb{\\boldsymbol{\\theta}}\n\\def\\tk{\\boldsymbol{\\theta}_k}\n\\def\\tj{\\boldsymbol{\\theta}_j}\n\\def\\Mk{\\boldsymbol{{\\cal M}}_k}\n\\def\\M{\\boldsymbol{{\\cal M}}}\n\\def\\Mj{\\boldsymbol{{\\cal M}}_j}\n\\def\\Mi{\\boldsymbol{{\\cal M}}_i}\n\\def\\Mg{{\\boldsymbol{{\\cal M}_\\gamma}}}\n\\def\\Mnull{\\boldsymbol{{\\cal M}}_{N}}\n\\def\\gMPM{\\boldsymbol{\\gamma}_{\\text{MPM}}}\n\\def\\gHPM{\\boldsymbol{\\gamma}_{\\text{HPM}}}\n\\def\\Mfull{\\boldsymbol{{\\cal M}}_{F}}\n\\def\\NS{\\boldsymbol{{\\cal N}}}\n\\def\\tg{\\boldsymbol{\\theta}_{\\boldsymbol{\\gamma}}}\n\\def\\g{\\boldsymbol{\\gamma}}\n\\def\\eg{\\boldsymbol{\\eta}_{\\boldsymbol{\\gamma}}}\n\\def\\G{\\mathbf{G}}\n\\def\\cM{\\cal M}\n\\def\\D{\\boldsymbol{\\Delta}}\n\\def\\Dbf{\\mathbf{D}}\n\\def \\shat{{\\hat{\\sigma}}^2}\n\\def\\uv{\\mathbf{u}}\n\\def\\l {\\lambda}\n\\def\\d{\\delta}\n\\def\\deltab{\\mathbf{\\delta}}\n\\def\\Sigmab{\\boldsymbol{\\Sigma}}\n\\def\\Phib{\\boldsymbol{\\Phi}}\n\\def\\Lambdab{\\boldsymbol{\\Lambda}}\n\\def\\lambdab{\\boldsymbol{\\lambda}}\n\\def\\Mg{{\\cal M}_\\gamma}\n\\def\\S{{\\cal{S}}}\n\\def\\Sbf{{\\mathbf{S}}}\n\\def\\qg{p_{\\boldsymbol{\\gamma}}}\n\\def\\pg{p_{\\boldsymbol{\\gamma}}}\n\\def\\T{\\boldsymbol{\\Theta}}\n\\def\\Tb{\\boldsymbol{\\Theta}}\n\\def\\t{\\mathbf{t}}\n\n\n\nHypothesis Testing:\n\n\n  \n- Testing submodels \n  - Extra sum of squares \n  - F-tests \n  - Null distribution\n  - Decision procedure \n  - P-values\n  \n- Testing individual coefficients\n  - t-tests\n\n- Likelihood Ratio Tests\n\n  \n. . .\n\nReadings:\n\n- Christensen Appendix C, Chapter 3\n\n\n## Testing Recap\n\n-  We assume the Gaussian Linear Model\n$$\\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\text{M1} \\quad \\Y ∼ \\N(\\W\\alphav + \\X\\b, \\sigma^2\\I) \\equiv \\N(\\Z\\tb, \\sigma^2\\I)$$\nwhere $\\W$ is $n \\times q$, $\\X$ is $n \\times p$, $\\Z = [\\W \\X]$, \n\n- We wish to evaluate the hypothesis $\\b = \\zero$ \n\n- equivalent to comparing M1 to M0:\n$$\\text{M0} \\quad \\Y ∼ \\N(\\W\\alphav, \\sigma^2\\I)$$\n- $\\SSE_{M0}/(n-q)$ and $\\SSE_{M1}/(n- q - p)$ are unbiased estimates of $\\sigma^2$ under null model M0\n\n- but the ratio $\\frac{\\SSE_{M0}/(n-q)}{\\SSE_{M1}/(n- q - p)}$ does not have a F distribution\n\n\n\n\n## Extra Sum of Squares\n\nRewrite $\\SSE_{M0}$:\n\\begin{align*}\n\\SSE_{M0} & = \\Y^T(\\I - \\P_{\\W})\\Y \\\\\n          & = \\Y^T(\\I - \\P_{\\Z} + \\P_{\\Z} - \\P_{\\W})\\Y \\\\\n          & = \\Y^T(\\I - \\P_{\\Z})\\Y + \\Y^T(\\P_{\\Z} - \\P_{\\W})\\Y \\\\\n          & = \\SSE_{M1} + \\Y^T(\\P_{\\Z} - \\P_{\\W})\\Y \n\\end{align*}\n\n. . .\n\nExtra Sum of Squares:\n$$\\SSE_{M0} - \\SSE_{M1}  = \\Y^T(\\P_{\\Z} - \\P_{\\W})\\Y$$\n\n## Expectation of Extra Sum of Squares\n\n\n$\\E[\\SSE_{M0} - \\SSE_{M1}] = \\E[\\Y^T(\\P_{\\Z} - \\P_{\\W})\\Y]$\n\n- under M0: $\\mub = \\W\\alphav$\n\\begin{align*} \n\\E[(\\P_{\\Z} - \\P_{\\W})\\Y] & = \\P_{\\Z}\\W\\alphav - \\P_{\\W}\\W\\alphav \\\\\n & = \\W\\alphav \\W_\\alphav  \\\\ \n & = \\zero \\\\\n\\E[\\Y^T(\\P_{\\Z} - \\P_{\\W})\\Y] & = \\sigma^2(\\tr \\P_\\Z + \\tr \\P_\\W) \\\\\n & = \\sigma^2 (q + p - q) = p \\sigma^2\n\\end{align*}\n\n- under M1: $\\mub = \\X\\b + \\W\\alphav$\n\\begin{align*} \n\\E[(\\P_{\\Z} - \\P_{\\W})\\Y] & = \\X\\b + \\W\\alphav - \\P_{\\W}\\X\\b - \\W\\alphav \\\\\n & = (\\I - \\P_{\\W})\\X\\b \\\\\n\\E[\\Y^T(\\P_{\\Z} - \\P_{\\W})\\Y] & = p \\sigma^2 + \\b^T\\X^T(\\I - \\P_{\\W})\\X\\b\n\\end{align*}\n\n## Test Statistic\n\nPropose ratio:\n$$F = \\frac{(\\SSE_{M0} - \\SSE_{M1})/p} {\\SSE_{M1}/(n - q - p)} = \\frac{\\Y^T(\\P_{\\Z} - \\P_{\\W})\\Y/p}{\\SSE_{M1}/(n - q - p)}$$\nas a test statistic.\n\n. . .\n\nDoes $F$ have an F distribution under M0? \n\n  - denominator $\\SSE_{M1}/\\sigma^2$ does have a $\\chi^2$ distribution?\n  - does numerator $\\SSE_{M0}/\\sigma^2$ have a $\\chi^2$ distribution?\n  - are they independent?\n \n \n## Properties of $\\P_{\\Z} - \\P_{\\W}$\n\nTo show that $\\Y^T(\\P_{\\Z} - \\P_{\\W})\\Y$ has a $\\chi^2$ distribution under M0 or M1, we need to show that $\\P_{\\Z} - \\P_{\\W}$ is a projection matrix.\n\n- symmetric?\n- idempotent?\n\n. . .\n\n\\begin{align*}\n(\\P_{\\Z} - \\P_{\\W})^2 & = \\P_{\\Z}^2 - \\P_{\\Z}\\P_{\\W} - \\P_{\\W}\\P_{\\Z} + \\P_{\\W}^2 \\\\\n & = \\P_{\\Z} - \\P_{\\Z}\\P_{\\W} - \\P_{\\W}\\P_{\\Z} + \\P_{\\W} \\\\\n & = \\P_{\\Z} - \\P_{\\Z}\\P_{\\W} - (\\P_{\\Z}\\P_{\\W})^T + \\P_{\\W} \\\\\n & = \\P_{\\Z} - 2\\P_{\\W}  + \\P_{\\W} \\\\\n & = \\P_{\\Z} - \\P_{\\W}\n\\end{align*} \n\n- Note: we are using $\\P_{\\Z}\\P_{\\W} = \\P_{\\W}$ as each column of $\\P_{\\W}$\nis in $C(\\W)$ and hence also in $C(\\Z)$\n\n. . .\n\nSo $\\P_{\\Z} - \\P_{\\W}$ is a projection matrix\n\n::: footer\n:::\n\n## Projection Matrix $\\P_{\\Z} - \\P_{\\W}$\n  \nOnto what space is it projecting? \n\n- Intuitively, it is projecting onto the part of $\\X$ that is not in $\\W$, $\\tX = (\\I - \\P_{\\W})\\X$ (the part of $\\X$ that is orthogonal to $\\W$)\n\n- $C(\\tX)$ and $C(\\W)$ are complementary orthogonal subspaces of $C(\\Z)$\n\n- $\\P_{\\Z} - \\P_{\\W}$ is a projection matrix onto $C(\\tX)$ along $C(\\W)$\n\n- we are decomposing $C(\\Z)$ into two orthogonal subspaces $C(\\W)$ and $C(\\tX)$\n\n- We can write $\\P_{\\Z} = \\P_{\\tX} + \\P_{\\W}$  where $\\P_{\\tX} \\P_{\\W} = \\P_{\\W} \\P_{\\tX} = \\zero$ \n\n. . .\n\nNote: we can always write \n\\begin{align*}\n\\mub & = \\W\\alphav + \\X\\b \\\\\n     & = \\W\\alphav + (\\I - \\P_{\\W})\\X\\b + \\P_{\\W}\\X\\b \\\\\n     & = \\W \\tilde{\\alphav} + \\tX\\b\n\\end{align*}\n\n## Distribution of Extra Sum of Squares\n\n- Since $\\P_{\\Z} - \\P_{\\W}$ is a projection matrix \n- $\\Y^T(\\P_{\\Z} - \\P_{\\W})\\Y/\\sigma^2$ has a $\\chi^2_p$ distribution under M0\n\n. . .\n\n\\begin{align*}\n\\Y^T(\\P_{\\Z} - \\P_{\\W})\\Y & = \\|(\\P_{\\Z} - \\P_{\\W})\\Y\\|^2 \\\\\n & = \\|(\\P_{\\Z} - \\P_{\\W})(\\X\\b + \\W\\alpha + \\eps\\|^2 \\\\\n& = \\|(\\P_{\\Z} - \\P_{\\W})(\\X\\b \\eps\\|^2 \\\\\n & = \\|(\\P_{\\Z} - \\P_{\\W})\\eps\\|^2 \\quad \\text{ if } \\b = \\zero\\\\\n & = \\eps^T(\\P_{\\Z} - \\P_{\\W})\\eps \\\\\n & \\sim \\sigma^2 \\chi^2_p \\quad \\text{ if } \\b = \\zero\n\\end{align*} \n\n- show that $\\Y^T(\\P_{\\Z} - \\P_{\\W})\\Y$ and $\\Y^T(\\I - \\P_{\\Z})\\Y$ are independent\n\n## F-Statistic\nUnder M1: $\\b = \\zero$\n\n\\begin{align*}\nF(\\Y) & = \\frac{(\\SSE_{M0} - \\SSE_{M1})/p}{\\SSE_{M1}/(n - q - p)} \\\\\n      & = \\frac{(\\SSE_{M0} - \\SSE_{M1})/\\sigma^2p}{\\SSE_{M1}/\\sigma^2(n - q - p)} \\\\\n      & \\eqindis \\frac{\\chi^2_p/p}{\\chi^2_{n-q-p}/(n-q-p)} \\\\\n      & \\eqindis F_{p, n-q-p}\n\\end{align*}\n\n- Under M1, $\\Y^T(\\P_{\\Z} - \\P_{\\W})\\Y/\\sigma^2$ has a non-central $\\chi^2_{p, \\eta}$ where the non-centrality parameter $\\eta = \\b^T\\X^T(\\I - \\P_{\\W})\\X\\b/2\\sigma^2$. \n\n- $F$ has a non-central F distribution with $p$ and $n-q-p$ degrees of freedom and non-centrality parameter $\\eta = \\b^T\\X^T(\\I - \\P_{\\W})\\X\\b/2\\sigma^2$\n(See Christensen Theorem 3.2.1 and Appendix C)\n\n::: footer\n:::\n\n## Testing Individual Coefficients\n\nConsider the model with $p = 1$, $\\Y = \\W\\alphav + \\x\\beta + \\eps$  and we want to test that $\\beta = 0$ (M0)\n\n1. fit the full model and compute $\\SSE_{M1}$\n2. fit the reduced model and compute $\\SSE_{M0}$\n3. calculate the $F$ statistic and $p$-value\n\n. . .\n\nIt turns out that we can obtain this $F$ statistic by fitting the full model  and the test reduces to a familiar $t$-test\n\n. . .\n\n\\begin{align*}\n\\hspace{-1in}{\\text{Note: }} \\hspace{1in} \\SSE_{M0} - \\SSE_{M1} & =  \\Y^T(\\P_{\\Z} - \\P_{\\W})\\Y  \\\\\n& = \\|(\\P_{\\tX} + \\P_{\\W} - \\P_{\\W})\\Y\\|^2 \\\\\n& = \\|\\P_{\\tX}\\Y\\|^2 \\\\\n& = \\|(\\I - \\P_{\\W})\\X\\bhat\\|^2 \\\\\n& = \\bhat^T\\X^T(\\I - \\P_{\\W})\\X\\bhat\n\\end{align*}\n\n## Testing Individual Coefficients\n\nFor $p = 1$, the $F$ statistic\n\n\\begin{align*}\nF(\\Y) & = \\frac{(\\SSE_{M0} - \\SSE_{M1})/1}{\\SSE_{M1}/(n - q - 1)} \\\\\n  & = \\frac{\\hat{\\beta}^T\\x^T(\\I - \\P_{\\W})\\x\\hat{\\beta}}{s^2} \\\\\n  & = \\frac{\\hat{\\beta}^2}{s^2/\\x^T(\\I - \\P_{\\W})\\x} \\\\\nF(\\Y)   & \\sim F_{1, n - q - 1}  \\quad \\text{ under } \\beta = 0\n\\end{align*}\n\n. . .\n\n- variance of $\\hat{\\beta}$:\n\\begin{align*}\n\\var[\\hat{\\beta}] & = \\sigma^2/\\x^T(\\I - \\P_{\\W})\\x = \\sigma^2 v\\\\\nv & = 1/\\x^T(\\I - \\P_{\\W})\\x\n\\end{align*}\n\n## $t$-statistic\n\n\\begin{align*}\nF(\\Y) & = \\frac{\\hat{\\beta}^2}{s^2/\\x^T(\\I - \\P_{\\W})\\x} \n= \\left(\\frac{\\hat{\\beta}}{s \\sqrt{v}}\\right)^2 \n=  t(\\Y)^2\n\\end{align*}\n\n- Since $F(\\Y) \\sim F(1, n - q - 1)$ under M0: $\\beta = 0$, \n$t(\\Y)^2 \\sim F(1,n - q - 1)$ under M0: $\\beta = 0$\n\n- what is distribution of $t(\\Y)$ under M0: $\\beta \\ne 0$?\n\n. . .\n\nRecall that under M0: $\\beta = 0$, \n\n1. $\\hat{\\beta}/\\sqrt{v\\sigma^2} \\sim \\N(0, 1)$\n2. $(n-q-1)s^2/\\sigma^2 \\sim \\chi^2_{n-q-1}$\n3. $\\hat{\\beta}$ and $s^2$ are independent\n\n\n## Student $t$ Distribution\n\n::: {.Theorem}\n### Student $t$ Distribution\nA random variable $T$ has a Student $t$ distribution with $\\nu$ degrees of freedom if \n$$T \\eqindis \\frac{Z}{X/\\nu}$$\n\nwhere \n\\begin{align*}\nZ & \\sim \\N(0,1) \\\\\nX & \\sim \\chi^2_\\nu \\\\\nZ &\\text{ and }  X \\text{ are independent }\n\\end{align*}\n:::\n\n\n\n\n- $\\therefore \\, t(\\Y) = \\hat{\\beta}/\\sqrt{v\\sigma^2}$ has a Student $t$ distribution with $n - q - 1$\ndegrees of freedom under M0: $\\beta = 0$\n\n## Decision rules and $p$-values\n\n::: {.columns}\n:::: {.column width=60%}\n- an $F_{1, \\nu}$ is equal in distribution to the square of Student $t_{\\nu}$ distribution\nunder the null model (also equal in distribution under the full model, but have a non-centrality parameter)\n\n- Decision rule was to reject M0 if $F(\\Y) > F_{1, n - q - 1, \\alpha}$\n\n- $p$-value is $\\Pr(F_{1, n - q - 1} > F(\\Y)$; the probability of observing a value of $F$ as extreme as the observed value under the null model\n\n- using a t-distribution, the equivalent decision rule is to reject M0 if $|t(\\Y)| > t_{n - q - 1, \\alpha/2}$\n\n- $p$-value is $\\Pr(|T_{n - q - 1}| > |t(\\Y)|)$\n\n- equal-tailed $t$-test\n:::\n:::: {.column width=40%}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](14-testing-submodels_files/figure-revealjs/p-value-1.png){fig-align='center' width=3.5in height=6.5in}\n:::\n:::\n\n\n:::\n::::\n\n## Likelihood Ratio Tests\n\n- we derived the $F$-test heurestically, but the formally this test may be derived as a likelihood ratio test.\n\n- consider a statistical model $\\Y \\sim P,  P \\in \\{P_\\tb: \\tb \\in \\Tb\\}$\n\n- $P$ is the true unknown distribution for $\\Y$\n\n- $\\{P_\\tb: \\tb \\in \\Tb\\}$ is the model, the set of possible distributions for $\\Y$ with $\\Tb$ the parameter space\n\n- we might hypothesize that $\\tb \\subset \\Tb_0 \\subset \\Tb$\n\n- for our linear model this translates as $\\tb = (\\alphav, \\b, \\sigma^2) \\subset \\bbR^q \\times \\{\\zero\\} \\times \\bbR ^+ \\subset \\bbR^g \\times \\bbR^p \\times \\bbR^+$\n\n- compute the **likelihood ratio statistic**\n$$R(\\Y) = \\frac{\\sup_{\\tb \\in \\Tb_0} p_\\tb(\\Y))}{\\sup_{\\tb \\in \\Tb} p_\\tb(\\Y))}$$\n\n## Likelihood Ratio Tests\n\nEquivalently, we can look at **-2 times the log likelihood ratio statistic**\n$$\\lambda(\\Y) = -2\\log(R(\\Y)) = -2 [\\sup_{\\tb \\in \\Tb_0} \\cal{l}(\\tb)- \\sup_{\\tb \\in \\Tb} \\cal{l}(\\tb)]$$\nwhere $\\cal{l}(\\tb) \\propto \\log p_\\tb(\\Y)$ (the log likelihood)\n\n. . .\n\n\nSteps: \n\n  1. Find the MLEs of $\\tb$ in the reduced model $\\Tb_0$, $\\hat{\\tb}_0$\n  2. Find the MLEs of $\\tb the full model $\\Tb$, $\\hat{\\tb}$\n  3. Compute $\\lambda(\\Y) = -2 [\\cal{l}(\\hat{\\tb}_0)- \\cal{l}(\\hat{\\tb})]$\n  4. Find the distribution of $\\lambda(\\Y)$ under the reduced model\n\n. . .\n\nwith some rearranging and 1-to-1 transformations, can show that this is equivalent to the $F$-test!  \n",
    "supporting": [
      "14-testing-submodels_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/font-awesome/css/all.min.css\" rel=\"stylesheet\" />\n<link href=\"../../site_libs/font-awesome/css/v4-shims.min.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}