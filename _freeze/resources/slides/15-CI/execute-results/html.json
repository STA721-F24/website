{
  "hash": "53ef01c6682ffa4c1509e84027b3d49a",
  "result": {
    "engine": "knitr",
    "markdown": "---\nsubtitle: \"STA 721: Lecture 15\"\ntitle: \"Confidence Regions\"\nauthor: \"Merlise Clyde (clyde@duke.edu)\"\ninstitute: \"Duke University\"\nformat: \n  revealjs:\n    theme: [simple, custom.scss]\n    slide-number: true\n    incremental: true\n    scrollable: false\n    controls: true\n    fragments: true\n    preview-links: auto\n    smaller: true\n    logo: ../../img/icon.png\n    footer: <https://sta721-F24.github.io/website/>\n    chalkboard: \n      boardmarker-width: 1\n      chalk-width: 2\n      chalk-effect: 0\n    embed-resources: false\n    include-in-header: mathjax-eq.html\nhtml-math-method:\n    method: mathjax\n    url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\neditor: \n  markdown: \n    wrap: 72\nexecute: \n  echo: false\nnumber-sections: false\nfilters:\n  - custom-numbered-blocks  \ncustom-numbered-blocks:\n  groups:\n    thmlike:\n      colors: [948bde, 584eab]\n      boxstyle: foldbox.simple\n      collapse: false\n      listin: [mathstuff]\n    todos: default  \n  classes:\n    Theorem:\n      group: thmlike\n      numbered: false\n    Lemma:\n      group: thmlike\n      numbered: false\n    Corollary:\n      group: thmlike\n      numbered: false\n    Proposition:\n      group: thmlike\n      numbered: false      \n    Proof:\n      group: thmlike\n      numbered: false\n      collapse: false   \n    Exercise:\n      group: thmlike\n      numbered: false\n    Definition:\n      group: thmlike\n      numbered: false\n      colors: [d999d3, a01793]\n    Feature: \n       numbered: false\n    TODO:\n      label: \"To do\"\n      colors: [e7b1b4, 8c3236]\n      group: todos\n      listin: [stilltodo]\n    DONE:\n      label: \"Done\"\n      colors: [cce7b1, 86b754]  \n      group: todos  \n---\n\n\n\n\n\n## Outline\n\n\\usepackage{xcolor}\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\DeclareMathOperator{\\sgn}{sgn}\n\\newcommand{\\e}{\\mathbf{e}}\n\\newcommand{\\Mb}{\\mathbf{M}}\n\\renewcommand{\\P}{\\mathbf{P}}\n\\newcommand{\\F}{\\mathbf{F}}\n\\newcommand{\\R}{\\textsf{R}}\n\\newcommand{\\mat}[1] {\\mathbf{#1}}\n\\newcommand{\\pen}{\\textsf{pen}}\n\\newcommand{\\E}{\\textsf{E}}\n\\newcommand{\\SE}{\\textsf{SE}}\n\\newcommand{\\SSE}{\\textsf{SSE}}\n\\newcommand{\\RSS}{\\textsf{RSS}}\n\\newcommand{\\FSS}{\\textsf{FSS}}\n\\renewcommand{\\SS}{\\textsf{SS}}\n\\newcommand{\\MSE}{\\textsf{MSE}}\n\\newcommand{\\SSR}{\\textsf{SSR}}\n\\newcommand{\\Be}{\\textsf{Beta}}\n\\newcommand{\\St}{\\textsf{St}}\n\\newcommand{\\Ca}{\\textsf{C}}\n\\newcommand{\\Lv}{\\textsf{LÃ©vy}}\n\\newcommand{\\Exp}{\\textsf{Exp}}\n\\newcommand{\\GDP}{\\textsf{GDP}}\n\\newcommand{\\NcSt}{\\textsf{NcSt}}\n\\newcommand{\\Bin}{\\textsf{Bin}}\n\\newcommand{\\NB}{\\textsf{NegBin}}\n\\newcommand{\\Mult}{\\textsf{MultNom}}\n\\renewcommand{\\NG}{\\textsf{NG}}\n\\newcommand{\\N}{\\textsf{N}}\n\\newcommand{\\Ber}{\\textsf{Ber}}\n\\newcommand{\\Poi}{\\textsf{Poi}}\n\\newcommand{\\Gam}{\\textsf{Gamma}}\n\\newcommand{\\BB}{\\textsf{BB}}\n\\newcommand{\\BF}{\\textsf{BF}}\n\\newcommand{\\Gm}{\\textsf{G}}\n\\newcommand{\\Un}{\\textsf{Unif}}\n\\newcommand{\\Ex}{\\textsf{Exp}}\n\\newcommand{\\DE}{\\textsf{DE}}\n\\newcommand{\\tr}{\\textsf{tr}}\n\\newcommand{\\cF}{{\\cal{F}}}\n\\newcommand{\\cL}{{\\cal{L}}}\n\\newcommand{\\cI}{{\\cal{I}}}\n\\newcommand{\\cB}{{\\cal{B}}}\n\\newcommand{\\cP}{{\\cal{P}}}\n\\newcommand{\\bbR}{\\mathbb{R}}\n\\newcommand{\\bbN}{\\mathbb{N}}\n\\newcommand{\\pperp}{\\mathrel{{\\rlap{$\\,\\perp$}\\perp\\,\\,}}}\n\\newcommand{\\OFP}{(\\Omega,\\cF, \\P)}\n\\newcommand{\\eps}{\\boldsymbol{\\epsilon}}\n\\def\\ehat{\\hat{\\boldsymbol{\\epsilon}}}\n\\newcommand{\\Psib}{\\boldsymbol{\\Psi}}\n\\newcommand{\\Omegab}{\\boldsymbol{\\Omega}}\n\\newcommand{\\1}{\\mathbf{1}_n}\n\\newcommand{\\gap}{\\vspace{8mm}}\n\\newcommand{\\ind}{\\mathrel{\\mathop{\\sim}\\limits^{\\rm ind}}}\n\\newcommand{\\iid}{\\mathrel{\\mathop{\\sim}\\limits^{\\rm iid}}}\n\\newcommand{\\simiid}{\\ensuremath{\\mathrel{\\mathop{\\sim}\\limits^{\\rm\niid}}}}\n\\newcommand{\\eqindis}{\\mathrel{\\mathop{=}\\limits^{\\rm D}}}\n\\newcommand{\\SSZ}{S_{zz}}\n\\newcommand{\\SZW}{S_{zw}}\n\\newcommand{\\Var}{\\textsf{Var}}\n\\newcommand{\\corr}{\\textsf{corr}}\n\\newcommand{\\cov}{\\textsf{cov}}\n\\newcommand{\\diag}{\\textsf{diag}}\n\\newcommand{\\var}{\\textsf{var}}\n\\newcommand{\\Cov}{\\textsf{Cov}}\n\\newcommand{\\Sam}{{\\cal S}}\n\\newcommand{\\VS}{{\\cal V}}\n\\def\\H{\\mathbf{H}}\n\\newcommand{\\I}{\\mathbf{I}}\n\\newcommand{\\Y}{\\mathbf{Y}}\n\\newcommand{\\tY}{\\tilde{\\mathbf{Y}}}\n\\newcommand{\\Yhat}{\\hat{\\mathbf{Y}}}\n\\newcommand{\\yhat}{\\hat{\\mathbf{y}}}\n\\newcommand{\\Yobs}{\\mathbf{Y}_{{\\cal S}}}\n\\newcommand{\\barYobs}{\\bar{Y}_{{\\cal S}}}\n\\newcommand{\\barYmiss}{\\bar{Y}_{{\\cal S}^c}}\n\\def\\bv{\\mathbf{b}}\n\\def\\X{\\mathbf{X}}\n\\def\\XtX{\\X^T\\X}\n\\def\\tX{\\tilde{\\mathbf{X}}}\n\\def\\x{\\mathbf{x}}\n\\def\\xbar{\\bar{\\mathbf{x}}}\n\\def\\Xbar{\\bar{\\mathbf{X}}}\n\\def\\Xg{\\mathbf{X}_{\\boldsymbol{\\gamma}}}\n\\def\\Ybar{\\bar{\\Y}}\n\\def\\ybar{\\bar{y}}\n\\def\\y{\\mathbf{y}}\n\\def\\Yf{\\mathbf{Y_f}}\n\\def\\W{\\mathbf{W}}\n\\def\\L{\\mathbf{L}}\n\\def\\m{\\mathbf{m}}\n\\def\\n{\\mathbf{n}}\n\\def\\w{\\mathbf{w}}\n\\def\\U{\\mathbf{U}}\n\\def\\V{\\mathbf{V}}\n\\def\\Q{\\mathbf{Q}}\n\\def\\Z{\\mathbf{Z}}\n\\def\\z{\\mathbf{z}}\n\\def\\v{\\mathbf{v}}\n\\def\\u{\\mathbf{u}}\n\n\\def\\zero{\\mathbf{0}}\n\\def\\one{\\mathbf{1}}\n\\newcommand{\\taub}{\\boldsymbol{\\tau}}\n\\newcommand{\\betav}{\\boldsymbol{\\beta}}\n\\newcommand{\\alphav}{\\boldsymbol{\\alpha}}\n\\newcommand{\\bfomega}{\\boldsymbol{\\omega}}\n\\newcommand{\\bfchi}{\\boldsymbol{\\chi}}\n\\newcommand{\\bfLambda}{\\boldsymbol{\\Lambda}}\n\\newcommand{\\Lmea}{{\\cal L}} \n\\newcommand{\\scale}{\\bflambda} \n\\newcommand{\\Scale}{\\bfLambda} \n\\newcommand{\\bfscale}{\\bflambda} \n\\newcommand{\\mean}{\\bfchi}\n\\newcommand{\\loc}{\\bfchi}\n\\newcommand{\\bfmean}{\\bfchi}\n\\newcommand{\\bfx}{\\x}\n\\renewcommand{\\k}{g}\n\\newcommand{\\Gen}{{\\cal G}}\n\\newcommand{\\Levy}{L{\\'e}vy}\n\\def\\bfChi    {\\boldsymbol{\\Chi}}\n\\def\\bfOmega  {\\boldsymbol{\\Omega}}\n\\newcommand{\\Po}{\\mbox{\\sf P}}\n\\newcommand{\\A}{\\mathbf{A}}\n\\def\\a{\\mathbf{a}}\n\\def\\K{\\mathbf{K}}\n\\newcommand{\\B}{\\mathbf{B}}\n\\def\\b{\\boldsymbol{\\beta}}\n\\def\\bhat{\\hat{\\boldsymbol{\\beta}}}\n\\def\\btilde{\\tilde{\\boldsymbol{\\beta}}}\n\\def\\tb{\\boldsymbol{\\theta}}\n\\def\\bg{\\boldsymbol{\\beta_\\gamma}}\n\\def\\bgnot{\\boldsymbol{\\beta_{(-\\gamma)}}}\n\\def\\mub{\\boldsymbol{\\mu}}\n\\def\\tmub{\\tilde{\\boldsymbol{\\mu}}}\n\\def\\muhat{\\hat{\\boldsymbol{\\mu}}}\n\\def\\tb{\\boldsymbol{\\theta}}\n\\def\\tk{\\boldsymbol{\\theta}_k}\n\\def\\tj{\\boldsymbol{\\theta}_j}\n\\def\\Mk{\\boldsymbol{{\\cal M}}_k}\n\\def\\M{\\boldsymbol{{\\cal M}}}\n\\def\\Mj{\\boldsymbol{{\\cal M}}_j}\n\\def\\Mi{\\boldsymbol{{\\cal M}}_i}\n\\def\\Mg{{\\boldsymbol{{\\cal M}_\\gamma}}}\n\\def\\Mnull{\\boldsymbol{{\\cal M}}_{N}}\n\\def\\gMPM{\\boldsymbol{\\gamma}_{\\text{MPM}}}\n\\def\\gHPM{\\boldsymbol{\\gamma}_{\\text{HPM}}}\n\\def\\Mfull{\\boldsymbol{{\\cal M}}_{F}}\n\\def\\NS{\\boldsymbol{{\\cal N}}}\n\\def\\tg{\\boldsymbol{\\theta}_{\\boldsymbol{\\gamma}}}\n\\def\\g{\\boldsymbol{\\gamma}}\n\\def\\eg{\\boldsymbol{\\eta}_{\\boldsymbol{\\gamma}}}\n\\def\\G{\\mathbf{G}}\n\\def\\cM{\\cal M}\n\\def\\D{\\boldsymbol{\\Delta}}\n\\def\\Dbf{\\mathbf{D}}\n\\def \\shat{{\\hat{\\sigma}}^2}\n\\def\\uv{\\mathbf{u}}\n\\def\\l {\\lambda}\n\\def\\d{\\delta}\n\\def\\deltab{\\mathbf{\\delta}}\n\\def\\Sigmab{\\boldsymbol{\\Sigma}}\n\\def\\Phib{\\boldsymbol{\\Phi}}\n\\def\\Lambdab{\\boldsymbol{\\Lambda}}\n\\def\\lambdab{\\boldsymbol{\\lambda}}\n\\def\\Mg{{\\cal M}_\\gamma}\n\\def\\S{{\\cal{S}}}\n\\def\\Sbf{{\\mathbf{S}}}\n\\def\\qg{p_{\\boldsymbol{\\gamma}}}\n\\def\\pg{p_{\\boldsymbol{\\gamma}}}\n\\def\\T{\\boldsymbol{\\Theta}}\n\\def\\Tb{\\boldsymbol{\\Theta}}\n\\def\\t{\\mathbf{t}}\n\n\n\n- Confidence Interverals from Test Statistics\n\n- Pivotal Quantities\n\n- Confidence intervals for parameters\n\n- Prediction Intervals\n\n. . .\n\nReadings:\n\n- Christensen Appendix C, Chapter 3\n\n\n\n## Goals\n\nFor the regression model $\\Y = \\X\\b +\\eps$ we usually want to do more than just\ntesting that $\\b$ is zero\n\n- what is a plausible range for $\\beta_j$?\n\n- what is a plausible set of values for $\\beta_j$ and $\\beta_k$?\n\n- what is a a plausible range of values for $\\x\\b$ for a particular $\\x$?\n\n- what is a plausible range of values for $\\Y_{n+1}$ for a given value of $\\x_{n+1}$?\n\n. . . \n\nLook at confidence intervals, confidence regions, prediction regions and Bayesian regions\n\n## Confidence Sets \n\nFor a random variable $\\Y \\sim \\P \\in \\{P_{\\tb}: \\tb \\in \\Tb\\}$\n\n::: {.Definition}\n## Confidence Region\nA set valued function $C$ is a $(1 - \\alpha) \\times 100\\%$ confidence region for $\\tb$\nif $$P_{\\tb}(\\{\\tb \\in C(\\Y)\\}) = 1- \\alpha \\, \\forall \\, \\tb \\in \\Tb$$\n:::\n\n- In this case we say $C(Y)$ is a $1 - \\alpha$ confidence region for the parameter $\\tb$\n\n- there is some true value of $\\tb$, and the confidence region will cover it with probability\n$1- \\alpha$ no matter what it is.\n\n- the randomness is due to $\\Y$ and $C(\\Y)$ \n\n- once we observe $\\Y$ everything is fixed, so region may not include the true $\\tb$\n\n## Hypothesis Tests and Rejection/Acceptance Regions\nRecall for a level $\\alpha$ test of a point null hypothesis\n\n- we reject $H$ with probability $\\alpha$ when $H$ is true\n\n- for each test we can construct:\n  - a rejection region $R(\\tb) \\subset \\cal{Y}$, the $Y$ values for which we reject $H$\n  - an acceptance region $A(\\tb)  \\subset \\cal{Y}$, the $Y$ values for which we accept $H$\n\n- these sets are complements of each other (for non-randomized tests)\n\n. . .\n\n$$\\Pr(\\Y \\in A(\\tb) \\mid \\tb) =  1 - \\alpha$$\n\n## Duality of Hypothesis-Testing/Confidence Regions\n\nSuppose we have a level $\\alpha$ test for every possible valuse of $\\tb$\n\n- for each $\\tb \\in \\Tb$, let $A(\\tb)$ be the acceptance region of the test $\\Y \\sim P_{\\tb}$\n\n- then $P(\\Y \\in A(\\tb) \\mid \\tb) = 1 - \\alpha$ for each $\\tb \\in \\Tb$\n\n- This collection of hypothesis tests can be âinvertedâ to construct a confidence region for Î¸, as follows: \n\n- define $C(\\Y) = \\{ \\tb \\in \\Tb: \\Y \\in A(\\tb) \\}$\n\n- this is the set of $\\tb$ values that are not rejected when $\\Y = \\y$ is observed\n\n- then $C$ is a $1 - \\alpha$ confidence region for $\\tb$\n\n\n## Confidence Intervals for Regression Parameters\n\nFor the linear model $\\Y \\sim \\N(\\X\\b, \\sigma^2 \\I)$, confidence intervals for $\\beta_j$ can be constructed from  inverting the approriate $t$-test.\n\n- suppose you are testing $H: \\beta_j = 0$\n\n- if $H$ is true, then\n  - $\\hat{\\beta}_j - \\beta_j \\sim \\N(0, \\sigma^2 v_{jj})$ where $v_{jj}$ is the $j$th diagonal element of $(\\X^T\\X)^{-1}$\n  - $s^2 \\sim \\sigma^2 \\chi^2_{n-p}/(n-p)$\n  - $\\hat{\\beta}_j$ and $s^2$ are independent\n- therefore if $H$ is true\n$$t_j = \\frac{\\hat{\\beta}_j - \\beta_j}{s\\sqrt{v_{jj}}} \\sim t_{n-p}$$\n\n\n## Acceptance Region & Confidence Interval\n- define the acceptance region \n$A(\\beta_j) = \\{ \\hat{\\beta}_j, s^2: |t_j| < t_{n-p, 1 - \\alpha/2}\\}$  \n- we have that $H$ is accepted if \n$$t_j \\in A(\\beta_j) \\Leftrightarrow \\frac{|\\hat{\\beta}_j - \\beta_j|}{s\\sqrt{v_{jj}}} < t_{n-p, 1-\\alpha/2}$$\n- Now construct a confidence interval for the true value by inverting the tests: \n\\begin{align*}\nC(\\hat{\\beta}_j, s^2) & =  (\\hat{\\beta_j}, s^2) \\in A(\\beta_j) \\\\\n & = \\left\\{ \\beta_j: |\\hat{\\beta}_j - \\beta_j| < s\\sqrt{v_{jj}} t_{n-p, 1 - \\alpha/2} \\right\\}\\\\\n& = \\left\\{ \\beta_j: \\hat{\\beta}_j - s\\sqrt{v_{jj}} t_{n-p, 1 - \\alpha/2} < \\beta_j < \\hat{\\beta}_j + s\\sqrt{v_{jj}} t_{n-p, 1 - \\alpha/2} \\right\\} \\\\\n& = \\hat{\\beta}_j \\pm s\\sqrt{v_{jj}}\\, t_{n-p, 1 - \\alpha/2}\n\\end{align*}\n\n- for $\\alpha = 0.05$ and large $n$, $t_{n-p,0.975} \\approx 2$, so CI is approximately $\\hat{\\beta}_j \\pm 2s\\sqrt{v_{jj}}$\n\n::: footer\n:::\n\n## Confidence Intervals for Linear Functions\n\nFor a linear function of the parameters $\\lambda = \\a^T \\b$ we can construct a confidence interval by inverting the appropriate $t$-test\n\n- most important example $\\a^T\\b = \\x^T\\b = \\E[\\Y \\mid \\x]$ \n- suppose you are testing $H: \\a^T\\b = m$\n- If $H$ is true, $\\a^T\\b - m \\sim \\N(0, \\sigma^2 v)$ where $v=\\a^T(\\X^T\\X)^{-1}\\a)$\n- $s^2 \\sim \\sigma^2 \\chi^2_{n-p}/(n-p)$ independent of $\\a^T\\hat{\\b}$\n- then $t = \\frac{\\a^T\\hat{\\b} - m}{s\\sqrt{v}} \\sim t_{n-p}$\n- a $1-\\alpha$ confidence interval for $\\a^T\\b$ is\n$$\\a^T\\hat{\\b} \\pm s\\sqrt{v}\\, t_{n-p, 1 - \\alpha/2}$$\n\n## Prediction Regions and Intervals\n\nRelated to CI for $\\E[Y \\mid \\x] = \\x^T\\b$, we may wish to construct a prediction interval for a new observation $Y^*$ at $\\x_*$\n\n- a $1-\\alpha$ prediction interval for $Y^*$ is a set valued function of $\\Y$, $C(\\Y)$ such that $$\\Pr(\\Y^* \\in C(\\Y) \\mid \\b,\\sigma^2) = 1 - \\alpha$$\nwhere the distribution is computed using the distribution of $\\Y^*$\n\n- this use the idea of a _pivotal quantity_: a function of the data and the parameters that has a known distribution that does not depend on any unknown parameters.\n\n- for prediction, $Y^* = \\x_*^T\\b + \\eps^*$ where $\\eps^* \\sim \\N(0, \\sigma^2)$ independent of $\\eps$\n\n. . .\n\n\\begin{align*}\n\\E[Y^* - \\x_*^T\\bhat]   & = \\x_*^T\\b - \\x_*^T\\b = 0 \\\\\n\\Var(Y^* - \\x_*^T\\bhat) & = \\Var(\\eps^*)  + \\Var(\\x_*^T\\bhat)   \n                         = \\sigma^2 + \\sigma^2 \\x_*^T(\\X^T\\X)^{-1}\\x_* \\\\\nY^* - \\x_*^T\\bhat & \\sim \\N(0, \\sigma^2(1 + \\x_*^T(\\X^T\\X)^{-1}\\x_*))\n\\end{align*}\n\n::: footer\n:::\n\n## Pivotal Quantity and Prediction Intervals\n\nSince $\\bhat$ and $s^2$ are independent, we can construct a pivotal quantity for $Y^* - \\x_*^T\\bhat$:\n$$\\frac{Y^* - \\x_*^T\\bhat}{s\\sqrt{1 + \\x_*^T(\\X^T\\X)^{-1}\\x_*}} \\sim t_{n-p}$$\n\n- therefore \n$$\\Pr\\left(\\frac{|Y^* - \\x_*^T\\bhat|}{s\\sqrt{1 + \\x_*^T(\\X^T\\X)^{-1}\\x_*}} < t_{n-p, 1-\\alpha/2} \\right) = 1 - \\alpha$$\n\n- Rearranging gives a $1-\\alpha$ prediction interval for $Y^*$:\n$$\\x_*^T\\bhat \\pm s\\sqrt{1 + \\x_*^T(\\X^T\\X)^{-1}\\x_*} t_{n-p, 1-\\alpha/2}$$\n\n## Joint Confidence Regions for $\\b$\n\n- we can construct a joint confidence region for $\\b$ based on inverting a test $H: \\b = \\b_0$. Recall:\n\n. . .\n\n\\begin{align*}\n\\bhat - \\b & \\sim \\N(0, \\sigma^2 (\\X^T\\X)^{-1}) \\\\\n(\\XtX)^{-1/2}(\\bhat - \\b) & \\sim \\N(0, \\sigma^2 \\I) \\\\\n(\\bhat - \\b)^T(\\XtX)^{-1}(\\bhat - \\b) & \\sim \\sigma^2 \\chi^2_p \n\\end{align*}\n\n- since $s^2$ is independent of $\\bhat$ we can construct a CI based on the $F$-distribution\n$$\\frac{(\\bhat - \\b_0)^T(\\XtX)^{-1}(\\bhat - \\b_0)/p}{s^2} \\sim F_{p, n-p}$$\n- inverting the $F$-test gives a $1-\\alpha$ confidence region for $\\b$:\n$$\\{ \\b: (\\bhat - \\b_0)^T(\\XtX)^{-1}(\\bhat - \\b_0)/s^2 < p F_{p, n-p, 1-\\alpha} \\}$$\n\n::: footer\n:::\n\n\n\n## Bayesian Credible Regions\n\n- In a Bayesian setting, we have a posterior distribution for $\\b$ given the data $\\Y$\n\n- a set $C \\in \\bbR^p$ is a $1-\\alpha$ posterior credible region (sometimes called a  Bayesian confidence region) if $\\Pr(\\b \\in C \\mid \\Y) = 1 - \\alpha$\n\n- lots of sets have this property, but we usually want the most probable values of $\\b$ given the data\n\n- this motivates looking at the highest posterior density (HPD) region which is a $1-\\alpha$ credible set $C$ such that the values in $C$ have higher posterior density than those outside of $C$ \n\n- the HPD region is the smallest region that contains $1-\\alpha$ of the posterior probability\n\n## Bayesian Credible Regions\n\n- For a normal prior and normal likelihood, the posterior for $\\b$ conditional on $\\sigma^2$ \n  is normal with say posterior mean $\\bv_n$ and posterior precision $\\Phib_n$\n\n- the posterior density as a function of $\\b$ for a fixed $\\sigma^2$ is\n$$p(\\b \\mid \\Y) \\propto \\exp\\left\\{ -(\\b - \\bv_n)^T \\Phib_n (\\b - \\bv_n)/2 \\right\\}$$\n- so a highest posterior density region has the form\n$$C = \\{ \\b: (\\b - \\bv_n)^T\\Phib_n^{-1}(\\b - \\bv_n)  < q \\}$$\n\n. . .\n\n\\begin{align*}\n\\b - \\b_n \\mid \\sigma^2 & \\sim \\N(0, \\Phib_n^{-1}) \\\\\n\\Phib_n^{1/2}(\\b - \\b_n) \\mid \\sigma^2 & \\sim \\N(0, \\I) \\\\\n(\\b - \\b_n)^T \\Phib_n (\\b - \\b_n) \\mid \\sigma^2 & \\sim  \\chi^2_p\n\\end{align*}\n\n- setting $q = \\chi^2_{p, 1-\\alpha}$ gives a Credible Region for  $\\Pr(\\b \\in C \\mid \\Y) = 1 - \\alpha$\n\n::: footer\n:::\n\n## Bayesian HPD Regions For Unknown $\\sigma^2$\n\n- For unknown $\\sigma^2$ we need to integrate out $\\sigma^2$ to get the marginal posterior for $\\b$\n\n- for conjugate priors, $\\b \\mid \\phi \\sim \\N(\\bv_0, (\\phi \\Phib_0)^{-1})$ and $\\phi \\mid \\Y \\sim \\G(a_n/2, b_n/2)$, then \n\\begin{align*}\n\\b \\mid \\phi, \\Y & \\sim \\N(\\bv_n, (\\phi \\Phib_n)^{-1}) \\\\\n\\phi \\mid \\Y & \\sim \\G(a_n/2, b_n/2) \\\\\n\\b \\mid \\Y & \\sim \\St(a_n, \\bv_n, \\hat{\\phi}\\Phib_n)\n\\end{align*}\nwhere $\\St(a_n, \\bv_n, (\\hat{\\phi}\\Phib_n)^{-1})$ is a multivariate Student-t distribution with $a_n$ degrees of freedom location $\\bv_n$ and scale matrix $(\\hat{\\phi}\\Phib_n)^{-1}$ with $\\hat{\\phi} = b_n/a_n$\n\n- Since $\\phi (\\b - \\bv_n)^T \\Phib_n (\\b - \\bv_n) \\sim \\chi^2_p$, show that the distribution of \n$$\\frac{\\phi (\\b - \\bv_n)^T \\Phib_n (\\b - \\bv_n)/p}{\\phi \\hat{\\phi}} \\sim F(p, a_n)$$\n- take $c = F_{p, a_n, 1-\\alpha}$ to get a $1-\\alpha$ HPD region for $\\b$\n\n\n\n\n\n  ",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/font-awesome/css/all.min.css\" rel=\"stylesheet\" />\n<link href=\"../../site_libs/font-awesome/css/v4-shims.min.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}